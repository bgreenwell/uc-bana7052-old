<!DOCTYPE html>
<html>
  <head>
    <title>Residual Diagnostics and Remedial Measures</title>
    <meta charset="utf-8">
    <meta name="author" content="Brandon M. Greenwell" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css/hygge.css" rel="stylesheet" />
    <script src="libs/htmlwidgets/htmlwidgets.js"></script>
    <script src="libs/plotly-binding/plotly.js"></script>
    <script src="libs/typedarray/typedarray.min.js"></script>
    <script src="libs/jquery/jquery.min.js"></script>
    <link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
    <script src="libs/crosstalk/js/crosstalk.min.js"></script>
    <link href="libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
    <script src="libs/plotly-main/plotly-latest.min.js"></script>
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Residual Diagnostics and Remedial Measures
## Lecture 04
### Brandon M. Greenwell
### 07 November, 2018

---

class: clear, middle



.font150[

* Required reading

    - Chapters: 3, 6, and 10

    - Sections: 3.1-3.4, 3.7, 6.8, and 10.1-10.4

* Main topics:

    - Diagnostic and Remedial Measures (3.1-3.4, 3.7, 6.8,)
  
    - Model Adequacy and Outlying Observations (10.1-10.4)

]


---

# Prerquisites

.scrollable[

.font125[


```r
# List of required (CRAN) packages
pkgs &lt;- c(
  NULL
)

# Install required (CRAN) packages
for (pkg in pkgs) {
  if (!requireNamespace(pkg)) {  # check if already installed
    install.packages(pkg)  # install it
  }
}

# Install additional (optional) awesomeness
install.packages(c("devtools", "magick"))
devtools::install_github("bgreenwell/roundhouse")
```

]

]


---
class: clear, center, middle

&lt;img src="lecture-04_files/figure-html/lets-go-1.svg" width="70%" style="display: block; margin: auto;" /&gt;


---
class: clear, center, middle, inverse

.font300[

What are *residual diagnostics* and *remedial measures* and why do we need them?

]


---
class: clear, center, middle, inverse

.font300[

What's wrong with my model and how do I fix it?

]


---
class: clear 

.font150[.bold[.center[.green[What are the typical assumptions of the linear regression model?]]]]

.font150[

`$$Y_i = \beta_0 + \beta_1 X_{i1} + \dots + \beta_{p-1} X_{i, p-1} + \epsilon_i\\i = 1, 2, \dots, n$$`

]

--

.font150[

* Independent observations: `\(Cov\left(\epsilon_i, \epsilon_j\right) = 0\)` `\(\left(i \ne j\right)\)`

]

--

.font150[

* Constant variance: `\(Var\left(\epsilon_i\right) = Cov\left(\epsilon_i, \epsilon_i\right) = \sigma^2\)`

]

--

.font150[

* Normally distributed errors: `\(\epsilon_i \stackrel{iid}{\sim} N\left(0, \sigma^2\right)\)` (.red[required for **traditional** statistical inference])

]

--

.font150[

* We assume that we have the .bold[.darkorange[correct model]]!

]


---
class: clear, center, middle, inverse

.font300[

How do we know if the model is ~~wrong~~ bad?

]


---
class: clear, center, middle

.font300[What is a residual?]

--

.font200[ 

`\(e_i = Y_i - \widehat{Y}_i\)` 

.font150.red[observed error = data - fit]

]


---

# What can residual plots tell us?

.font110[

* Plot of residuals against predictor variable (checking non-linearity).

* Plot of absolute or squared residuals against predictor variable (check non-constant variance)

* Plot of residuals against fitted values (non-constant variance and non-linearity)

* Plot of residuals against time or another sequence (non-independence)

* Plot of residuals against omitted predictor variables (missing potentially important predictors)

* Boxplot of residuals (outlying observations)

* Normal probability plot of residuals (non-normality).

]


---
class: clear, middle, center

&lt;img src="lecture-04_files/figure-html/example-diagnostics-1.svg" width="70%" style="display: block; margin: auto;" /&gt;


---

# Residual analysis

.font130[

* Residuals help in identifying a misspecified mean structure (i.e., `\(\boldsymbol{\beta}\boldsymbol{X}\)`)

* *Scaled residuals* help in identifying outliers or extreme values

* Common types of residuals:

    - Standardized Residuals
    
    - Studentized residuals
    
    - PRESS Residuals 

]


---
class: clear, middle, center

.font200[Normal Q-Q plots* can be used to asses the "normalityness" of a set of observations]

&lt;br&gt;&lt;br&gt;

*Q-Q plots can, in general, be used to compare data with any distirbution!


---
class: clear 

.code125[

```r
set.seed(101)
x &lt;- rnorm(100)
qqnorm(x, main = "Normal data")
qqline(x, lty = "dotted", col = "red2")
```

&lt;img src="lecture-04_files/figure-html/qqnorm-normal-1.svg" width="70%" style="display: block; margin: auto;" /&gt;
]


---
class: clear 

.code125[

```r
set.seed(101)
x &lt;- rlnorm(100)
qqnorm(x, main = "Skew right data")
qqline(x, lty = "dotted", col = "red2")
```

&lt;img src="lecture-04_files/figure-html/qqnorm-skew-right-1.svg" width="70%" style="display: block; margin: auto;" /&gt;
]


---
class: clear 

.code125[

```r
set.seed(101)
x &lt;- -rlnorm(100)
qqnorm(x, main = "Skew left data")
qqline(x, lty = "dotted", col = "red2")
```

&lt;img src="lecture-04_files/figure-html/qqnorm-skew-left-1.svg" width="70%" style="display: block; margin: auto;" /&gt;
]


---
class: clear 

.code125[

```r
set.seed(101)
x &lt;- rt(100, df = 1)
qqnorm(x, main = "Heavy-tailed data")
qqline(x, lty = "dotted", col = "red2")
```

&lt;img src="lecture-04_files/figure-html/qqnorm-heavy tails-1.svg" width="70%" style="display: block; margin: auto;" /&gt;
]


---
class: clear, middle, center

.font200[When should you use normality tests?]

--

&lt;img src="lecture-04_files/figure-html/never-1.svg" width="50%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

.font150[


```r
# Shapiro-Wilk test and sample size
set.seed(101)  # for reproducibility
x &lt;- replicate(100, c(
  shapiro.test(rt(10, df = 40))$p.value,
  shapiro.test(rt(100, df = 40))$p.value,
  shapiro.test(rt(1000, df = 40))$p.value,
  shapiro.test(rt(5000, df = 40))$p.value
))
rownames(x) &lt;- c("n=10", "n=100", "n=1000", "n=5000")
rowMeans(x &lt; 0.05)
```

```
*##   n=10  n=100 n=1000 n=5000 
*##   0.07   0.06   0.13   0.43
```

]


---
class: clear, middle, center

&lt;img src="lecture-04_files/figure-html/normal-vs-t-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle, center

.font300[Scaling the residuals]


---

# Standardized residuals

.font130[

`$$r_i^{stan} = \frac{r_i}{\sqrt{Var\left(r_i\right)}}$$`

* We want the standardized residuals to have .bold[mean zero] and .bold[unit variance]

]

--

.font150[

* Large positive/negative values of `\(r_i^{stan}\)`, say `\(\left|r_i^{stan}\right| &gt; 3\)` may indicate an outlier

]

--

.font150.center.content-box-blue[

So what is `\(Var\left(r_i\right)\)`? ü§î

]


---

# Standardized residuals

.font150[

* If `\(\epsilon_i \stackrel{iid}{\sim} N\left(0, \sigma^2\right)\)`, then `\(\epsilon_i/\sigma \stackrel{iid}{\sim} N\left(0, 1\right)\)`, so it seems intuitive to define a standardized residual as `$$r_i^{stan} =\frac{r_i}{\sqrt{MSE}} = \frac{r_i}{RMSE}$$`

]

--

.pull-left.font200.center.red[

However, `$$Var\left(r_i\right) \ne MSE$$` 

]

.pull-right[

&lt;img src="lecture-04_files/figure-html/say-what-1.svg" width="50%" style="display: block; margin: auto;" /&gt;

]


---

# Standardized residuals

.font140[

* Recall that `\(r_i = Y_i - \widehat{Y}_i\)`, or, in matrix form `$$\boldsymbol{r} = \boldsymbol{Y} - \widehat{\boldsymbol{Y}}$$`

* It can be shown that the variance of `\(r_i\)` is given by `\(\sigma^2\left(1 - h_{ii}\right)\)`, which can be estimated with `\(MSE\left(1 - h_{ii}\right)\)`

]

--

.font140[

* .purple[Studentized residual]: `\(r_i^{stud} = \frac{r_i}{\sqrt{MSE\left(1 - h_{ii}\right)}}\)`

    - Variance of residuals depends on `\(\boldsymbol{X}\)`

    - More effective at detecting outlying response values

]


---

# PRESS residuals

.font115[

* Another refinement to make the residuals more effective at detecting outlying `\(Y\)` observations is to measure the *i*-th residual `\(r_i = Y_i - \widehat{Y}_i\)` when the fitted regression is based on all of the cases except the *i*-th one

    - Also referred to as the __*deleted residuals*__ or __*jackknife residuals*__

    - A form of *leave one out cross-validation* (LOOCV)

* It can be shown that these residuals can be obtained without refitting the model `\(n\)` times using `$$r_i^{PRESS} = d_i = \frac{r_i}{1 - h_{ii}}$$`

* PRESS statistic: `\(PRESS = \sum_{i=1}^n d_i^2\)` (.red[useful for model building/selection])

]


---
class: clear, middle, center

&lt;img src="images/residual-patterns.png" width="70%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

.code125[


```r
# Load the delivery data
url &lt;- paste0("https://bgreenwell.github.io/",
              "uc-bana7052/data/delivery.csv")
delivery &lt;- read.csv(url)
head(delivery, n = 5)  # print first 5 observations
```

```
##   Index DeliveryTime NumberofCases Distance
## 1     1        16.68             7      560
## 2     2        11.50             3      220
## 3     3        12.03             3      340
## 4     4        14.88             4       80
## 5     5        13.75             6      150
```

]


---
class: clear, middle

.code110[


```r
# Fit an MLR model
delivery_fit &lt;- lm(DeliveryTime ~ NumberofCases + Distance, 
                   data = delivery)

# Fitted values
yhat &lt;- fitted(delivery_fit)
*# equivalent to `yhat &lt;- predict(delivery_fit)`

# Residuals
rorig &lt;- residuals(delivery_fit)  # ordinary
rstan &lt;- rstandard(delivery_fit)  # studentized
rstud &lt;- rstudent(delivery_fit)  # studentized deleted
press &lt;- rstandard(delivery_fit, type = "predict")  # PRESS
```

]


---

class: clear

.code90[


```r
getAnywhere("rstandard.lm")
```

```
## A single object matching 'rstandard.lm' was found
## It was found in the following places
##   registered S3 method for rstandard from namespace stats
##   namespace:stats
## with value
## 
## function (model, infl = lm.influence(model, do.coef = FALSE), 
##     sd = sqrt(deviance(model)/df.residual(model)), type = c("sd.1", 
##         "predictive"), ...) 
## {
##     type &lt;- match.arg(type)
##     res &lt;- infl$wt.res/switch(type, sd.1 = sd * sqrt(1 - infl$hat), 
##         predictive = 1 - infl$hat)
##     res[is.infinite(res)] &lt;- NaN
##     res
## }
## &lt;bytecode: 0x7fedd9894388&gt;
## &lt;environment: namespace:stats&gt;
```

]


---

class: clear

.code90[


```r
getAnywhere("rstudent.lm")
```

```
## A single object matching 'rstudent.lm' was found
## It was found in the following places
##   registered S3 method for rstudent from namespace stats
##   namespace:stats
## with value
## 
## function (model, infl = lm.influence(model, do.coef = FALSE), 
##     res = infl$wt.res, ...) 
## {
##     res &lt;- res/(infl$sigma * sqrt(1 - infl$hat))
##     res[is.infinite(res)] &lt;- NaN
##     res
## }
## &lt;bytecode: 0x7fedd9a65c68&gt;
## &lt;environment: namespace:stats&gt;
```

]


---
class: clear, middle, center

&lt;img src="lecture-04_files/figure-html/leverage-influence-1.svg" width="90%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle, center

.font200[Such problems are easy to see when there is only a single predictor!]


---

# Remedial measures

.center.font200[

What do we do once we've discovered inadequacies in the model?

]

--

* Misspecified mean structure: transformations and non-parametric algorithms (e.g., MARS or a decision tree), etc.

* Non-constant variance: transformations, *weighted least squares* (WLS), and *generalized linear models* (GLMs)

* Outliers and influential values: robust and resistant regression procedures

    - See `?MASS::rlm` and `?MASS::lqs` for some options

* Autocorrelation: time series modeling


---

# Your turn

.font175[

Return to the Boston housing example from the previous lecture. Fit an MLR model using `cmed` as the response and `lstat` and `rm` as the predictors. Check the adequacy of the fitted model using the methods discussed in this lecture. Does the model appear adequate? What assumptions, if any, appear to be violated? Are there potential outlying and/or influential values?

]


---
class: clear, middle, center

&lt;img src="lecture-04_files/figure-html/boston-spm-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

.code100[




```r
library(broom)
library(dplyr)
pdp::boston %&gt;%
  lm(cmedv ~ lstat + rm, data = .) %&gt;%
  broom::augment() %&gt;%
  mutate(row_num = 1:n()) %&gt;%
  head(5)
```

```
## # A tibble: 5 x 11
##   cmedv lstat    rm .fitted .se.fit .resid    .hat .sigma .cooksd
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1  24    4.98  6.58    29.0   0.367 -4.96  0.00446   5.50 1.22e-3
## 2  21.6  9.14  6.42    25.5   0.275 -3.89  0.00249   5.50 4.18e-4
## 3  34.7  4.03  7.18    32.7   0.419  2.03  0.00579   5.51 2.67e-4
## 4  33.4  2.94  7.00    32.4   0.417  0.976 0.00574   5.51 6.10e-5
## 5  36.2  5.33  7.15    31.6   0.396  4.57  0.00519   5.50 1.21e-3
## # ... with 2 more variables: .std.resid &lt;dbl&gt;, row_num &lt;int&gt;
```

]


---
class: clear, middle, center

&lt;img src="lecture-04_files/figure-html/boston-residual-plots-01-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle, center

&lt;img src="lecture-04_files/figure-html/boston-residual-plots-02-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle, center

&lt;img src="lecture-04_files/figure-html/boston-residual-plots-03-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle, center

&lt;img src="lecture-04_files/figure-html/boston-residual-plots-04-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle, center

&lt;img src="lecture-04_files/figure-html/boston-residual-plots-05-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle, center

.font300[Leverage values]


---

# Hidden extrapolation in MLR

.pull-left[

* It is never a good idea to make predictions outside the region covered by the training data

    - This region is difficult to visualize whenever `\(k &gt; 2\)`
    
    - The diagonal entries of `\(\boldsymbol{H}\)`, denoted `\(h_{ii}\)`, can be useful for detecting outlying cases
    
    - `\(X_{new}\)` is considered "outlying" if `\(h_{new} = \boldsymbol{X}_{new}^\top\left(\boldsymbol{X}^\top\boldsymbol{X}\right)^{-1}\boldsymbol{X}_{new}\)` lies outside of the range of the diagonal entries of `\(\boldsymbol{H}\)`
    
    - See `?influence.measures`

]

.pull-right[

.middle[

&lt;img src="lecture-04_files/figure-html/chull-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

]


---
class: clear, middle

.code80[


```r
# Which training observations might be considered as outliers?
h &lt;- hatvalues(delivery_fit)
plot(h, type = "h", ylim = extendrange(h, f = 0.15))
*abline(h = 2 * 3 / nrow(delivery), lty = "dotted")
text(h, labels = seq_len(nrow(delivery)), pos = 3, col = "red2")
```

&lt;img src="lecture-04_files/figure-html/delivery-hatvalue-1.svg" width="70%" style="display: block; margin: auto;" /&gt;
]


---
class: clear, middle

.code80[


```r
# Determine outlyingness of new observations
X &lt;- model.matrix(delivery_fit)
head(X)
```

```
##   (Intercept) NumberofCases Distance
## 1           1             7      560
## 2           1             3      220
## 3           1             3      340
## 4           1             4       80
## 5           1             6      150
## 6           1             7      330
```

```r
X_new &lt;- rbind(c(1, 10, 1000), c(1, 40, 3))
(h_new &lt;- diag(X_new %*% solve(t(X) %*% X) %*% t(X_new)))
```

```
## [1] 0.4028795 4.1354043
```

```r
h_new &gt; max(abs(h))
```

```
## [1] FALSE  TRUE
```

]


---
class: clear, middle

.font200[

Using base R functionality (see `?plot.lm` for details):

]

.code125[


```r
# Set up plotting grid
par(mfrow = c(2, 3))  # three rows and two columns
plot(delivery_fit, which = 1:6)
```

]


---
class: clear, middle, center

&lt;img src="lecture-04_files/figure-html/base-residual-plots-02-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle, center

.font300[Multicollinearity]


---

# Multicolinearity

* In many (typically non-experimental) situations, the predictor variables tend to be correlated among themselves

* When this correlation is "high", *multicollinearity* is said to exist

* Multicollinearity does not, in general, prevent us from obtaining a good fit! It can, however, cause other issues:

    - **Multicollinearity can** cause some of the estimated coefficients to become unstable (i.e., high standard errors)
    
    - **Multicollinearity can** complicate the interpretation of the estimated coefficients (e.g., predicting crop yield from the amount of rainfall and hours of sunshine)
    
* A simple way to assess whether or not multicollinearity is present is to use *variance inflation factors* (VIFs)

    - VIFs are available from the R package [car](https://cran.r-project.org/package=car) as the next example illustrates


---

# Heart catheter example

.font150[

A study was conducted and data collected to fit a regression model to predict the length of a catheter needed to pass from a major artery at the femoral region and moved into the heart for children (Weisberg 1980). For 12 children, the proper catheter length was determined by checking with a fluoroscope that the catheter tip had reached the right position. The goal is to determine a model where a child‚Äôs height and weight could be used to predict the proper catheter length.

]

.font150.center[

[heart.R](https://github.com/bgreenwell/stt7140-env/blob/master/code/heart.R)

]


---
class: clear, middle

.code100[


```r
# Load required packages
library(car)     # for vif() function
library(plotly)  # for interactive plotting

# Load the data
url &lt;- "https://bgreenwell.github.io/uc-bana7052/data/heart"
heart &lt;- read.table(url, header = TRUE)
head(heart, 5)  
```

```
##   Height Weight Length
## 1   42.8   40.0     37
## 2   63.5   93.5     50
## 3   37.5   35.5     34
## 4   39.5   30.0     36
## 5   45.5   52.0     43
```

]


---
class: clear, middle


```r
GGally::ggpairs(heart)  # scatterplot matrix
```

&lt;img src="lecture-04_files/figure-html/heart-02-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

.code150[


```r
# Correlation matrix
(cor_mat &lt;- cor(heart))
```

```
##           Height    Weight    Length
## Height 1.0000000 0.9610936 0.8927873
## Weight 0.9610936 1.0000000 0.9045102
## Length 0.8927873 0.9045102 1.0000000
```

]


---
class: clear, middle

<div id="htmlwidget-250a90e3defbe182559d" style="width:100%;height:504px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-250a90e3defbe182559d">{"x":{"visdat":{"6c055237739d":["function () ","plotlyVisDat"]},"cur_data":"6c055237739d","attrs":{"6c055237739d":{"x":{},"y":{},"z":{},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"Weight (pounds)"},"yaxis":{"title":"Height (inches)"},"zaxis":{"title":"Length (cm)"}},"hovermode":"closest","showlegend":false},"source":"A","config":{"modeBarButtonsToAdd":[{"name":"Collaborate","icon":{"width":1000,"ascent":500,"descent":-50,"path":"M487 375c7-10 9-23 5-36l-79-259c-3-12-11-23-22-31-11-8-22-12-35-12l-263 0c-15 0-29 5-43 15-13 10-23 23-28 37-5 13-5 25-1 37 0 0 0 3 1 7 1 5 1 8 1 11 0 2 0 4-1 6 0 3-1 5-1 6 1 2 2 4 3 6 1 2 2 4 4 6 2 3 4 5 5 7 5 7 9 16 13 26 4 10 7 19 9 26 0 2 0 5 0 9-1 4-1 6 0 8 0 2 2 5 4 8 3 3 5 5 5 7 4 6 8 15 12 26 4 11 7 19 7 26 1 1 0 4 0 9-1 4-1 7 0 8 1 2 3 5 6 8 4 4 6 6 6 7 4 5 8 13 13 24 4 11 7 20 7 28 1 1 0 4 0 7-1 3-1 6-1 7 0 2 1 4 3 6 1 1 3 4 5 6 2 3 3 5 5 6 1 2 3 5 4 9 2 3 3 7 5 10 1 3 2 6 4 10 2 4 4 7 6 9 2 3 4 5 7 7 3 2 7 3 11 3 3 0 8 0 13-1l0-1c7 2 12 2 14 2l218 0c14 0 25-5 32-16 8-10 10-23 6-37l-79-259c-7-22-13-37-20-43-7-7-19-10-37-10l-248 0c-5 0-9-2-11-5-2-3-2-7 0-12 4-13 18-20 41-20l264 0c5 0 10 2 16 5 5 3 8 6 10 11l85 282c2 5 2 10 2 17 7-3 13-7 17-13z m-304 0c-1-3-1-5 0-7 1-1 3-2 6-2l174 0c2 0 4 1 7 2 2 2 4 4 5 7l6 18c0 3 0 5-1 7-1 1-3 2-6 2l-173 0c-3 0-5-1-8-2-2-2-4-4-4-7z m-24-73c-1-3-1-5 0-7 2-2 3-2 6-2l174 0c2 0 5 0 7 2 3 2 4 4 5 7l6 18c1 2 0 5-1 6-1 2-3 3-5 3l-174 0c-3 0-5-1-7-3-3-1-4-4-5-6z"},"click":"function(gd) { \n        // is this being viewed in RStudio?\n        if (location.search == '?viewer_pane=1') {\n          alert('To learn about plotly for collaboration, visit:\\n https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html');\n        } else {\n          window.open('https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html', '_blank');\n        }\n      }"}],"cloud":false},"data":[{"x":[42.8,63.5,37.5,39.5,45.5,38.5,43,22.5,37,23.5,33,58],"y":[40,93.5,35.5,30,52,17,38.5,8.5,33,9.5,21,79],"z":[37,50,34,36,43,28,37,20,34,30,38,47],"type":"scatter3d","mode":"markers","marker":{"color":"rgba(31,119,180,1)","line":{"color":"rgba(31,119,180,1)"}},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"base_url":"https://plot.ly"},"evals":["config.modeBarButtonsToAdd.0.click"],"jsHooks":[]}</script>


---
class: clear, middle


```r
# Fit a linear model
heart_fit &lt;- lm(Length ~ Height + Weight, data = heart)
summary(heart_fit)
```

```
## 
## Call:
## lm(formula = Length ~ Height + Weight, data = heart)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.7419 -1.2034 -0.2595  1.8892  6.6566 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  20.3758     8.3859   2.430    0.038 *
*## Height        0.2107     0.3455   0.610    0.557  
*## Weight        0.1911     0.1583   1.207    0.258  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.778 on 9 degrees of freedom
*## Multiple R-squared:  0.8254,	Adjusted R-squared:  0.7865 
*## F-statistic: 21.27 on 2 and 9 DF,  p-value: 0.0003888
```


---
class: clear, middle

.code150[


```r
# Compute variance inflation factors
*vif(heart_fit)
```

```
##   Height   Weight 
## 13.10633 13.10633
```

]

--

.font150[

* Both variance inflation factors are greater than 10 üò±

]

--

.font150.center.content-box-blue[

What are some potential remedies?

]



---

# Remedies for multicollinearity

.font150[

* Omit some of the predictors

]

--

.font150[

* Standardize the predictor column(s) (.blue[useful in polyomial models])

]

--

.font150[

* [*Regularized regression*](https://koalaverse.github.io/AnalyticsSummit18/03-Regularization.html#1)

    - Ridge regression
    
    - The LASSO

]


---

# Your turn üò±

.font150[

Return to the Boston housing example from the previous lecture. Fit an MLR model using `cmed` as the response and `lstat` and `rm` as the predictors. Does multicollinearity appear to be an issue here? Explain.

]


---

# Solution üòé

.font150[


```r
# Compute VIF scores for the Boston housing example
pdp::boston %&gt;%
  lm(cmedv ~ lstat + rm, data = .) %&gt;%
  vif()
```

```
##   lstat      rm 
## 1.60452 1.60452
```

]

--

.center[.font300[

üëç

]]


---

# Other useful diagnostics

.font150[

* DFFITS

* DFBETAS

* Cook's distance

]


---
class: clear, middle, center

&lt;img src="lecture-04_files/figure-html/quittin-time-1.svg" width="60%" style="display: block; margin: auto;" /&gt;
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
