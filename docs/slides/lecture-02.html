<!DOCTYPE html>
<html>
  <head>
    <title>Inferences in Simple Linear Regression</title>
    <meta charset="utf-8">
    <meta name="author" content="Brandon M. Greenwell" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css/hygge.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Inferences in Simple Linear Regression
## Lecture 02
### Brandon M. Greenwell
### 16 September, 2018

---

class: clear 



background-image: url(images/research-walberg-normal-distribution.jpg)


---

# Reading assignment

.larger[

* Chapter: 2

    - Sections: TBD

* Main topics: TBD
  
]


---

# Prerquisites

.scrollable[


```r
# List of required (CRAN) packages
pkgs &lt;- c(
  "animation",  # for pre-built statistical animations
  "dplyr",      # for data wrangling
  "ggplot2",    # for awesome graphics
  "HistData",   # for historical data sets
  "tibble"      # for nicer data frames
)

# Install required (CRAN) packages
for (pkg in pkgs) {
  if (!requireNamespace(pkg)) {  # check if already installed first
    install.packages(pkg)  # install it
  }
}

# Install additional (optional) awesomeness
install.packages(c("devtools", "magick"))
devtools::install_github("bgreenwell/roundhouse")
```

]


---

# Ready to begin?

--


```r
roundhouse::kick("Chuck Norris counted to infinity, twice", 
                 width = 50)
```

&lt;img src="lecture-02_files/figure-html/roundhouse-01-1.gif" width="70%" style="display: block; margin: auto;" /&gt;


---
class: clear 

background-image: url(images/significance.png)
background-size: 40%


---
class: clear, middle

&lt;img src="lecture-02_files/figure-html/relationship-01-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

&lt;img src="lecture-02_files/figure-html/relationship-02-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

&lt;img src="lecture-02_files/figure-html/relationship-03-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---

# Inferences concerning `\(\beta_1\)`

.large[

* **Bad:** Is there a relationship between `\(X\)` and `\(Y\)`? (.red[not testable])

]

--

.large[

* **Good:** Is there a statistically significant linear relationship between `\(X\)` and `\(Y\)` at the `\(\alpha = 0.05\)` level? (.green[testable])

]

--

.large[

* How can we reformulate this as a statistical test?

]

--

.large[

$$
H_0: \beta_1 = 0 \quad vs \quad H_1: \beta_1 \ne 0
$$

]

--

.large[

* Need a point estimate, test statistic, reference distribution, etc.

]


---

# Properties of `\(\widehat{\beta}_1\)`

.large[

* Recall from the previous lecture that LS estimation provides the best linear unbiased estimates .blue[(BLUE)] of `\(\beta_0\)` and `\(\beta_1\)`; namely, `\(\widehat{\beta}_0\)` and `\(\widehat{\beta}_1\)`

    - Unbiased since `\(E\left[\widehat{\beta}_0\right] = \beta_0\)` and `\(E\left[\widehat{\beta}_1\right] = \beta_1\)`

    - Best in the sense that `\(\widehat{\beta}_0\)` and `\(\widehat{\beta}_1\)` have the smallest .purple[variance] among all other **linear unbiased** estimators of `\(\beta_0\)` and `\(\beta_1\)`, respectively

]

--

.large[

* So what is `\(Var\left[\widehat{\beta}_0\right]\)` and `\(Var\left[\widehat{\beta}_1\right]\)`?

]


---

# Properties of `\(\widehat{\beta}_1\)`

.large[

* Recall that the LS estimate of the slope is a weighted average of the (observed) response values: `\(\widehat{\beta}_1 = \sum_{i=1}^n w_iY_i\)` 

]

--

.large[

* Since the `\(Y_i\)` are independent, it follows that 

.small[

`$$Var\left(\widehat{\beta}_1\right) = Var\left(\sum_{i=1}^n w_iY_i\right) = \sum_{i=1}^n w_i^2Var\left(Y_i\right) = \dots = \sigma^2 / S_{xx}$$`

]

]


---

# Sampling distribution of `\(\widehat{\beta}_1\)`

.large[

* Assuming `\(\epsilon_i \stackrel{iid}{\sim} N\left(0, \sigma^2\right)\)`, then `\(\widehat{\beta}_1 \sim ???\)` ü§î

]

--
 
.large[

* `\(\widehat{\beta}_1 \sim N\left(\beta_1, \sigma^2/S_{xx}\right)\)`

]

--

.large[

* But we generally don't know `\(\sigma^2\)`, so how do we estimate it?

]

--

.large[

* Replace `\(\sigma^2\)` with its point estimate ($\widehat{\sigma}^2 = MSE$), and the sampling distribution of `\(\widehat{\beta}_1\)` becomes `\(\widehat{\beta}_1 \stackrel{\cdot}{\sim} N\left(\beta_1, \widehat{\sigma}^2/S_{xx}\right)\)`

]


---

# Standard errors

.large[

* .purple[The standard deviation of an estimate is referred to as its *standard error*]. For example,

`$$\sqrt{Var\left(\widehat{\beta}_1\right)} = SE\left(\widehat{\beta}_1\right) = \sigma/\sqrt{S_{xx}}$$`

]

--

.large[

* Since we don't know `\(\sigma^2\)`, we estimate `\(SE\left(\widehat{\beta}_1\right) = \sigma/\sqrt{S_{xx}}\)` with its *plug-in* estimate

`$$\widehat{SE}\left(\widehat{\beta}_1\right) = \widehat{\sigma}/\sqrt{S_{xx}}$$`

]


---

# Inference regarding `\(\beta_1\)`

* Hypothesis test: `\(H_0: \beta_1 = c \quad vs \quad H_1: \beta_1 \ne c\)`

--

* Test statistic: `$$t_{obs} = \frac{\widehat{\beta}_1 - c}{\widehat{SE}\left(\widehat{\beta}_1\right)} = \frac{\widehat{\beta}_1 - c}{\widehat{\sigma} / \sqrt{S_{xx}}}$$`

--

* Rejection `\(H_0\)` whenever `\(\left|t_{obs}\right| \ge t_{n - 2, 1 - \alpha/2}\)`

    - In R, `\(t\)` quantiles can be obtained using `qt(1 - alpha/2, df = n-2)`, for example
    

```r
alpha &lt;- 0.05           # significance level
n &lt;- 30                 # sample size         
*qt(1 - alpha/2, n - 2)  # cutoff value
```

```
## [1] 2.048407
```

--

* A `\(\left(1-\alpha\right)\)` 100% confidence interval for `\(\beta_1\)` is given by `\(\widehat{\beta}_1 \pm t_{n - 2, 1 - \alpha/2}\widehat{\sigma}/S_{xx}\)`


---

# Rocket propellant example

.scrollable[


```r
# Load the rocket propellant data
rocket &lt;- read.csv("https://bgreenwell.github.io/uc-bana7052/data/rocket.csv")

# Fit an SLR model
rocket_fit &lt;- lm(strength ~ age, data = rocket)

# Plot the data with the fitted mean response
investr::plotFit(rocket_fit)
```

&lt;img src="lecture-02_files/figure-html/02-rocket-01-1.png" width="70%" style="display: block; margin: auto;" /&gt;

```r
# Print a summary of the fitted model
summary(rocket_fit)
```

```
## 
## Call:
## lm(formula = strength ~ age, data = rocket)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -215.98  -50.68   28.74   66.61  106.76 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 2627.822     44.184   59.48  &lt; 2e-16 ***
## age          -37.154      2.889  -12.86 1.64e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 96.11 on 18 degrees of freedom
## Multiple R-squared:  0.9018,	Adjusted R-squared:  0.8964 
## F-statistic: 165.4 on 1 and 18 DF,  p-value: 1.643e-10
```

```r
# Compute a 95% CI for the slope
*confint(rocket_fit, level = 0.95)
```

```
##                  2.5 %    97.5 %
## (Intercept) 2534.99540 2720.6493
## age          -43.22338  -31.0838
```

]


---
class: clear, middle

.large[

Can you interpret the confidence interval for `\(\beta_1\)` in the previous example?

]

--


```r
confint(rocket_fit, level = 0.95)
```

```
##                  2.5 %    97.5 %
## (Intercept) 2534.99540 2720.6493
## age          -43.22338  -31.0838
```

With 95% confidence, we estimate that the mean strength of rockets decreases between 31.08 psi and 43.22 psi for every one-week increase in age.


---

# Your turn üò±

.huge[

Fit an SLR model to the crystal weight data using `weight` as the response and `time` as the predictor. Find a 95% confidence interval for the slope and interpret the results in **plain english**.

]


---

# Solution üôå

.scrollable[


```r
# Load the crystal weight data
data(crystal, package = "investr")

# Fit an SLR model
crystal_fit &lt;- lm(weight ~ time, data = crystal)

# Plot the data with the fitted mean response
investr::plotFit(crystal_fit)
```

&lt;img src="lecture-02_files/figure-html/01-crystal-solution-01-1.png" width="70%" style="display: block; margin: auto;" /&gt;

```r
# Print a summary of the model
summary(crystal_fit)
```

```
## 
## Call:
## lm(formula = weight ~ time, data = crystal)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.96371 -0.73464  0.05629  0.89193  1.40800 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.001429   0.599387   0.002    0.998    
## time        0.503429   0.035197  14.303 6.69e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.062 on 12 degrees of freedom
## Multiple R-squared:  0.9446,	Adjusted R-squared:   0.94 
## F-statistic: 204.6 on 1 and 12 DF,  p-value: 6.688e-09
```

```r
# Compute a 95% CI for the regression coefficients
*confint(crystal_fit, level = 0.95)
```

```
##                  2.5 %    97.5 %
## (Intercept) -1.3045241 1.3073812
## time         0.4267404 0.5801168
```

With 95% confidence, we estimate that the average weight of crystals increases between 0.43 grams and 0.58 grams for every one-hour increase in growth time.

]


---

# Rocket propellant example

.scrollable[

Using the rocket propellant example, test whether the slope significantly differes from `\(-40\)` psi/week at the `\(\alpha = 0.05\)` level.


```r
# Extract summary of estimated slope
*(slope &lt;- summary(rocket_fit)$coef["age", ])
```

```
##      Estimate    Std. Error       t value      Pr(&gt;|t|) 
## -3.715359e+01  2.889107e+00 -1.285989e+01  1.643344e-10
```

```r
# Compute test statistic
(t_obs &lt;- (slope["Estimate"] + 40) / slope["Std. Error"])  # &lt;&lt;
```

```
##  Estimate 
## 0.9852212
```

```r
# Compute cutoff from reference distribution
alpha &lt;- 0.05
n &lt;- nrow(rocket)
*(t_ref &lt;- qt(1 - alpha/2, df = n - 2))
```

```
## [1] 2.100922
```

```r
# Decision rule
if (abs(t_obs) &gt; t_ref) "reject H0" else "fail to reject H0"
```

```
## [1] "fail to reject H0"
```

]


---

# Your turn üò±

.large[

Using the crystal weight example, test whether the slope significantly differes from `\(3/4\)` grams/hour at the `\(\alpha = 0.1\)` level.

]


---

# Solution üôå

.large[

`$$H_0: \beta_1 = 3/4 \quad vs \quad H_1: \beta_1 \ne 3/4$$`


```r
# Compute a 90% CI for the slope
confint(crystal_fit, parm = "time", level = 0.9)
```

```
##           5 %      95 %
## time 0.440697 0.5661602
```

Since 3/4 lies outside of the 90% confidence interval for `\(\beta_1\)`, we reject the null hypoethsis at the 0.1 level and conclude that the slope significantly differs from 3/4. 

]


---

# Computing the *p*-value

.scrollable[

* One-sided test: `$$p = Pr\left(T_{n-2} &gt; \left|t_{obs}\right|\right)$$`

* Two-sided test: `$$p = 2 \times Pr\left(T_{n-2} &gt; \left|t_{obs}\right|\right)$$`


```r
*# From the rocket propellant example. What test does this correspond to?
*(t_obs &lt;- slope["Estimate"] / slope["Std. Error"])
```

```
##  Estimate 
## -12.85989
```

```r
*(p_val &lt;- 2 * pt(abs(t_obs), df = nrow(rocket) - 2, lower.tail = FALSE))
```

```
##     Estimate 
## 1.643344e-10
```

]


---

# Your turn üò±

.large[

Compute the *p*-value for the previous test in the crystal weight example. What is your decision?

]


---

# Solution üôå

.medium[

`$$H_0: \beta_1 = 3/4 \quad vs \quad H_1: \beta_1 \ne 3/4$$`


```r
slope &lt;- summary(crystal_fit)$coef["time", ]
*(t_obs &lt;- (slope["Estimate"] - 3/4) / slope["Std. Error"])
```

```
##  Estimate 
## -7.005421
```

```r
*(p_val &lt;- 2 * pt(abs(t_obs), df = nrow(crystal) - 2, lower.tail = FALSE))
```

```
##     Estimate 
## 1.423506e-05
```

Since `\(p &lt; 0.1\)`, we reject the null hypothesis and conclude that the slope significantly differs from 3/4. 

]


---

# Inferences concerning `\(\beta_0\)`

* Similar results exist for the intercept, just replace `\(\widehat{SE}\left(\widehat{\beta}_1\right)\)` with `$$\widehat{SE}\left(\widehat{\beta}_0\right) = MSE\left(\frac{1}{n} + \frac{\bar{X}^2}{S_{xx}}\right)$$`


---
class: clear

.larger[

Consider the following hypotheses for the SLR model: `$$H_0: \beta_1 = 0 \quad vs \quad H_1: \beta_1 \ne 0$$`

]

--

.larger[

.center[

.red[

What does failing to reject `\(H_0\)` imply about the relationship between `\(X\)` and `\(Y\)`?

]

]

]


---

# ANOVA approach

.large[

* What does ANOVA refer to? ü§î

]

--

.large[

* Partitioning sums of squares (SS)

    - Total SS: `\(SST = SS_{tot} = \sum_{i=1}^n\left(Y_i - \bar{Y}\right)^2\)`
    
    - Error SS: `\(SSE = SS_{err} = \sum_{i=1}^n\left(Y_i - \widehat{Y}_i\right)^2\)`
    
    - Regression SS: `\(SSR = SS_{reg} = \sum_{i=1}^n\left(\widehat{Y}_i - \bar{Y}\right)^2\)`
    
]


---

# ANOVA approach

.large[

* `\(\left(Y_i - \bar{Y}\right) = \left(\widehat{Y}_i - \bar{Y}\right) + \left(Y_i - \widehat{Y}_i\right)\)`

]

-- 

.large[

* It is easy to show that the sums of these squared deviations have the same relationship: `$$\sum_{i=1}^n\left(Y_i - \bar{Y}\right) = \sum_{i=1}^n\left(\widehat{Y}_i - \bar{Y}\right) + \sum_{i=1}^n\left(Y_i - \widehat{Y}_i\right)$$`

    - In other words, `\(SST = SSS + SSE\)` (.purple[much like in a one-way ANOVA])

]


---

# ANOVA approach

.larger[

* Diving an SS by its associated *degrees of freedome* (df) produces mean squares (.purple[kind of like a standard deviation])

]

--

.larger[

* `\(MSR = \frac{SSR}{1}\)`

* `\(MSE = \frac{SSE}{1}\)`

]


---
class: clear, inverse, middle, center

.huge[

Is there a (linear) relationship between `\(X\)` and `\(Y\)`? `$$H_0: \beta_1 = 0 \quad vs \quad H_1: \beta_1 \ne 0$$`

]


---

# ANOVA approach

.large[

* Test statistic: `$$F_{obs} = \frac{MSR}{MSE}$$` with 1 .darkorange[numerator degrees of freedom] and `\(n-2\)` .darkorange[denominator degrees of freedom]

]

--

.large[

* Reject `\(H_0\)` at the `\(\alpha\)` level whenever `\(F_{obs} &gt; F_{1-\alpha, 1, n-2}\)`

    - Notice the use of `\(\alpha\)` as opposed to `\(\alpha/2\)` ü§î
    
    - Is a large value of `\(F_{obs}\)` good or bad?

]


---

# Rocket propellant example

.scrollable[


```r
# Compute ANOVA table for the fitted model
*anova(rocket_fit)
```

```
## Analysis of Variance Table
## 
## Response: strength
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## age        1 1527483 1527483  165.38 1.643e-10 ***
## Residuals 18  166255    9236                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

```r
# Print summary of fitted model
summary(rocket_fit)
```

```
## 
## Call:
## lm(formula = strength ~ age, data = rocket)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -215.98  -50.68   28.74   66.61  106.76 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 2627.822     44.184   59.48  &lt; 2e-16 ***
## age          -37.154      2.889  -12.86 1.64e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 96.11 on 18 degrees of freedom
## Multiple R-squared:  0.9018,	Adjusted R-squared:  0.8964 
## F-statistic: 165.4 on 1 and 18 DF,  p-value: 1.643e-10
```

```r
# Fit an intercept only model
rocket_fit_reduced &lt;- lm(strength ~ 1, data = rocket)
*mean(rocket$strength)  # compare to estimated intercept
```

```
## [1] 2131.358
```

```r
*anova(rocket_fit_reduced, rocket_fit)  # compare models
```

```
## Analysis of Variance Table
## 
## Model 1: strength ~ 1
## Model 2: strength ~ age
##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1     19 1693738                                  
## 2     18  166255  1   1527483 165.38 1.643e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

]

---

# Your turn üò±

.larger[

Using the crystal weight example, use an `\(F\)`-test to test whether or not there is a relationship between `time` and `weight` at the `\(\alpha = 0.05\)` level. Manually compute the *p*-value for this test and üôè that it matches the output from `summary()`.

]


---

# Solution üôå

.scrollable[


```r
# Print summary of the fitted model
summary(crystal_fit)
```

```
## 
## Call:
## lm(formula = weight ~ time, data = crystal)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.96371 -0.73464  0.05629  0.89193  1.40800 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.001429   0.599387   0.002    0.998    
## time        0.503429   0.035197  14.303 6.69e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.062 on 12 degrees of freedom
## Multiple R-squared:  0.9446,	Adjusted R-squared:   0.94 
## F-statistic: 204.6 on 1 and 12 DF,  p-value: 6.688e-09
```

```r
# What values can we pull out from summary()
names(summary(crystal_fit))
```

```
##  [1] "call"          "terms"         "residuals"     "coefficients" 
##  [5] "aliased"       "sigma"         "df"            "r.squared"    
##  [9] "adj.r.squared" "fstatistic"    "cov.unscaled"
```

```r
# Observed test statitic
f_obs &lt;- summary(crystal_fit)$fstatistic

# Compute p-value (one approach)
pf(f_obs, df1 = 1, df2 = nrow(crystal) - 2, lower.tail = FALSE)
```

```
##        value        numdf        dendf 
## 6.687884e-09 3.370491e-01 4.681605e-03
```

```r
# Compute p-value (another approach)
1 - pf(f_obs, df1 = 1, df2 = nrow(crystal) - 2)
```

```
##        value        numdf        dendf 
## 6.687884e-09 3.370491e-01 4.681605e-03
```

]
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
